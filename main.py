"""
main.py - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì§„ì…ì 
Selenium ê¸°ë°˜ 3ëŒ€ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ í†µí•© í¬ë¡¤ë§ â†’ ê°ì„± ë¶„ì„ â†’ ì‹œê°í™” â†’ ì—‘ì…€ ì €ì¥
"""

from crawler import MultiSiteCrawler
from sentiment import SentimentAnalyzer
from visualizer import DashboardVisualizer
from exporter import DataExporter
from datetime import datetime


def run_pipeline(keyword: str, pages_per_site: int = 3,
                 sites: list = None):
    """
    Args:
        keyword:        ê²€ìƒ‰ í‚¤ì›Œë“œ
        pages_per_site: ì‚¬ì´íŠ¸ë‹¹ ìˆ˜ì§‘ í˜ì´ì§€ ìˆ˜
        sites:          ìˆ˜ì§‘ ì‚¬ì´íŠ¸ ëª©ë¡ (None=ì „ì²´)
                        ì˜ˆ: ["naver", "hankyung"]
    """
    print("=" * 60)
    print(f"  ğŸ“° News Sentiment Insight Dashboard")
    print(f"  í‚¤ì›Œë“œ: [{keyword}] | ì‚¬ì´íŠ¸ë‹¹ {pages_per_site}p")
    print(f"  ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # STEP 1: ë©€í‹°ì‚¬ì´íŠ¸ í¬ë¡¤ë§
    print("\n[STEP 1] ğŸ” 3ëŒ€ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì¤‘...")
    crawler = MultiSiteCrawler(sites=sites)
    df = crawler.crawl_to_df(keyword=keyword, pages_per_site=pages_per_site)

    if df.empty:
        print("  âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n  ğŸ“Š ì‚¬ì´íŠ¸ë³„ ìˆ˜ì§‘ í˜„í™©:")
    for site, count in df["source"].value_counts().items():
        print(f"     {site}: {count}ê±´")
    print(f"  í•©ê³„: {len(df)}ê±´")

    # STEP 2: ê°ì„± ë¶„ì„
    print("\n[STEP 2] ğŸ§  ê°ì„± ì ìˆ˜ ì‚°ì¶œ ì¤‘...")
    analyzer = SentimentAnalyzer()
    df = analyzer.analyze(df)
    stats = analyzer.get_statistics(df)
    print(f"  ê¸ì •: {stats['positive']}ê±´({stats['pos_ratio']}%)"
          f" | ë¶€ì •: {stats['negative']}ê±´({stats['neg_ratio']}%)"
          f" | í‰ê· ì ìˆ˜: {stats['avg_score']:+}")

    # STEP 3: ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
    print("\n[STEP 3] ğŸ“Š ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
    viz = DashboardVisualizer(keyword=keyword)
    viz.create_dashboard(df)
    print("  âœ… output/dashboard.png ì €ì¥ ì™„ë£Œ")

    # STEP 4: ì—‘ì…€ ì €ì¥
    print("\n[STEP 4] ğŸ“‚ ì—‘ì…€ ì €ì¥ ì¤‘...")
    exporter = DataExporter(keyword=keyword)
    path = exporter.export(df)
    print(f"  âœ… {path} ì €ì¥ ì™„ë£Œ")

    print("\n" + "=" * 60)
    print("  ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 60)
    return df


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="News Sentiment Insight Dashboard")
    parser.add_argument("--keyword", "-k", type=str, default="ì‚¼ì„±ì „ì", help="Search keyword (default: ì‚¼ì„±ì „ì)")
    parser.add_argument("--pages", "-p", type=int, default=3, help="Pages per site (default: 3)")
    parser.add_argument("--sites", "-s", nargs="+", default=None, help="Specific sites to crawl (e.g., naver hankyung)")

    args = parser.parse_args()

    run_pipeline(args.keyword, args.pages, args.sites)
