"""
demo.py - ìƒ˜í”Œ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
Selenium/Chrome ì—†ì´ë„ 3ëŒ€ ì‚¬ì´íŠ¸ í†µí•© êµ¬ì¡°ì˜ ê²°ê³¼ë¬¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import pandas as pd
import random
from datetime import datetime, timedelta
from sentiment import SentimentAnalyzer
from visualizer import DashboardVisualizer
from exporter import DataExporter

SAMPLE_TITLES = [
    # ê¸ì •
    "ì‚¼ì„±ì „ì, 2ë¶„ê¸° ì˜ì—…ì´ìµ ê¸‰ë“±â€¦ë°˜ë„ì²´ í‘ì ì „í™˜ ì„±ê³µ",
    "ì½”ìŠ¤í”¼ 2600 ëŒíŒŒâ€¦ì™¸êµ­ì¸ ë§¤ìˆ˜ì„¸ ê°•ì„¸ ì§€ì†",
    "í˜„ëŒ€ì°¨, ê¸€ë¡œë²Œ ì „ê¸°ì°¨ íŒë§¤ 1ìœ„ ë‹¬ì„±â€¦ì„±ì¥ì„¸ ê°€ì†",
    "ë„¤ì´ë²„ AI ì‹ ì‚¬ì—… ìˆ˜ì£¼ ì‡ë‹¬ì•„â€¦ì£¼ê°€ ìƒí•œê°€",
    "LGì—ë„ˆì§€ì†”ë£¨ì…˜ ì‹ ê³ ê°€ ê²½ì‹ â€¦ìˆ˜ì£¼ ì”ê³  ê¸‰ì¦",
    "ì‚¼ì„± ë°˜ë„ì²´ ìˆ˜ì¶œ 30% ì¦ê°€â€¦ë¬´ì—­ìˆ˜ì§€ ê°œì„ ",
    "SKí•˜ì´ë‹‰ìŠ¤, HBM ë…ì  ê³µê¸‰ ê³„ì•½ íƒ€ê²°",
    "í˜„ëŒ€é‡, ì¹œí™˜ê²½ ì„ ë°• ìˆ˜ì£¼ ì‡ë”°ë¼ ì„±ì¥ ê°€ì†í™”",
    "í¬ìŠ¤ì½”, 2ì°¨ì „ì§€ ì†Œì¬ íˆ¬ì í™•ëŒ€ë¡œ ìœ ë§ì£¼ ì„ ì •",
    "ì¹´ì¹´ì˜¤ ì½˜í…ì¸  ë¶€ë¬¸ í˜¸ì¡°â€¦ì—°ê°„ í‘ì ì „í™˜ ê¸°ëŒ€",
    # ë¶€ì •
    "ì‚¼ì„±ì „ì ì£¼ê°€ ê¸‰ë½â€¦ë¯¸ì¤‘ ê°ˆë“± ì—¬íŒŒ ì¶©ê²©",
    "ì½”ìŠ¤í”¼ 3% í•˜ë½â€¦ê¸€ë¡œë²Œ ê¸´ì¶• ê³µí¬ ì¬ë¶€ê°",
    "ë¶€ë™ì‚° PF ìœ„ê¸°â€¦ê±´ì„¤ì‚¬ íŒŒì‚° ìš°ë ¤ í˜„ì‹¤í™”",
    "ì›ë‹¬ëŸ¬ í™˜ìœ¨ í­ë“±â€¦ì™¸í™˜ì‹œì¥ ë¶ˆì•ˆ ì‹¬í™”",
    "êµ­ë‚´ ìˆ˜ì¶œ ê°ì†Œì„¸ ì§€ì†â€¦ì œì¡°ì—… ì¹¨ì²´ ìš°ë ¤",
    "ê°€ê³„ë¶€ì±„ ê¸‰ì¦â€¦ê¸ˆìœµë‹¹êµ­ ê·œì œ ê°•í™” ê²½ê³ ",
    "ëŒ€ê¸°ì—… ì‹¤ì  ì‡¼í¬â€¦3ë¶„ê¸° ì˜ì—…ì´ìµ ëŒ€í­ ê°ì†Œ",
    "IT ê¸°ì—… ëŒ€ê·œëª¨ êµ¬ì¡°ì¡°ì •â€¦ê³ ìš© ë¶ˆì•ˆ í™•ëŒ€",
    "ë°˜ë„ì²´ ìˆ˜ìš” ë¶€ì§„ ì§€ì†â€¦ì—…í™© ì•…í™” ìš°ë ¤ ì¦ê°€",
    "í…ŒìŠ¬ë¼ ëŒ€ê·œëª¨ ë¦¬ì½œâ€¦ì „ê¸°ì°¨ ê²°í•¨ ë…¼ë€ í™•ëŒ€",
    # ì¤‘ë¦½
    "í•œêµ­ì€í–‰, ê¸°ì¤€ê¸ˆë¦¬ ë™ê²° ê²°ì •",
    "ê¸ˆìœµìœ„, ë‚´ë…„ ê¸ˆìœµì •ì±… ë°©í–¥ ë°œí‘œ",
    "ì‚¼ì„±ì „ì, 3ë¶„ê¸° ì‹¤ì  ë°œí‘œ ì˜ˆì •",
    "í˜„ëŒ€ì°¨, ì‹ ëª¨ë¸ ì¶œì‹œ ê³„íš ê³µê°œ",
    "LGì „ì ì‹ ì‚¬ì—… ì „ëµ ì„¤ëª…íšŒ ê°œìµœ",
]

SOURCES = ["naver", "daum", "hankyung"]
PRESS_BY_SOURCE = {
    "naver":    ["ì¡°ì„ ì¼ë³´", "ì¤‘ì•™ì¼ë³´", "ë™ì•„ì¼ë³´", "í•œêµ­ê²½ì œ", "ì—°í•©ë‰´ìŠ¤", "MBC"],
    "daum":     ["ì´ë°ì¼ë¦¬", "ë¨¸ë‹ˆíˆ¬ë°ì´", "í—¤ëŸ´ë“œê²½ì œ", "ë‰´ì‹œìŠ¤", "ë‰´ìŠ¤1"],
    "hankyung": ["í•œêµ­ê²½ì œ", "í•œê²½ë‹·ì»´"],
}


def generate_sample_data(keyword: str, n_per_site: int = 10) -> pd.DataFrame:
    random.seed(42)
    rows = []
    base = datetime.now()

    for source in SOURCES:
        for i in range(n_per_site):
            title = random.choice(SAMPLE_TITLES)
            if keyword not in title and random.random() > 0.4:
                title = title.replace("ì‚¼ì„±ì „ì", keyword)
            rows.append({
                "title":      title,
                "press":      random.choice(PRESS_BY_SOURCE[source]),
                "pub_time":   (base - timedelta(hours=random.randint(1, 48))).strftime("%Y.%m.%d %H:%M"),
                "url":        f"https://{source}.example.com/article/{i+1000}",
                "source":     source,
                "crawled_at": base.strftime("%Y-%m-%d %H:%M:%S"),
            })
    return pd.DataFrame(rows)


def run_demo(keyword: str = "ì‚¼ì„±ì „ì"):
    print("=" * 60)
    print("  ğŸ§ª ë°ëª¨ ëª¨ë“œ â€” ìƒ˜í”Œ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
    print(f"  í‚¤ì›Œë“œ: [{keyword}]")
    print("=" * 60)

    # STEP 1
    print("\n[STEP 1] ğŸ“¦ ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‚¬ì´íŠ¸ë³„ 10ê±´ Ã— 3)")
    df = generate_sample_data(keyword, n_per_site=10)
    print(f"  âœ… ì´ {len(df)}ê±´ ìƒì„±")
    for src, cnt in df["source"].value_counts().items():
        label = {"naver": "ë„¤ì´ë²„", "daum": "ë‹¤ìŒ", "hankyung": "í•œêµ­ê²½ì œ"}[src]
        print(f"     {label:6s}: {cnt}ê±´")

    # STEP 2
    print("\n[STEP 2] ğŸ§  ê°ì„± ë¶„ì„")
    analyzer = SentimentAnalyzer()
    df = analyzer.analyze(df)
    stats = analyzer.get_statistics(df)
    print(f"  ê¸ì •: {stats['positive']}ê±´ | ë¶€ì •: {stats['negative']}ê±´ | ì¤‘ë¦½: {stats['neutral']}ê±´")
    print(f"  í‰ê·  ê°ì„± ì ìˆ˜: {stats['avg_score']:+.3f}")

    # ì‚¬ì´íŠ¸ë³„ ê°ì„± ë¶„í¬
    print("\n  ğŸ“Š ì‚¬ì´íŠ¸ë³„ ê°ì„± ë¶„í¬:")
    site_labels = {"naver": "ë„¤ì´ë²„", "daum": "ë‹¤ìŒ", "hankyung": "í•œêµ­ê²½ì œ"}
    for src in SOURCES:
        sub = df[df["source"] == src]["sentiment"].value_counts()
        pos = sub.get("ê¸ì •", 0)
        neg = sub.get("ë¶€ì •", 0)
        neu = sub.get("ì¤‘ë¦½", 0)
        avg = df[df["source"] == src]["score"].mean()
        print(f"     {site_labels[src]:6s} | ê¸ì •:{pos} ë¶€ì •:{neg} ì¤‘ë¦½:{neu} | í‰ê· :{avg:+.2f}")

    # STEP 3
    print("\n[STEP 3] ğŸ“Š ëŒ€ì‹œë³´ë“œ ìƒì„±")
    viz = DashboardVisualizer(keyword=keyword)
    img = viz.create_dashboard(df)
    print(f"  âœ… {img}")

    # STEP 4
    print("\n[STEP 4] ğŸ“‚ ì—‘ì…€ ì €ì¥")
    exp = DataExporter(keyword=keyword)
    xlsx = exp.export(df)
    print(f"  âœ… {xlsx}")

    print("\n" + "=" * 60)
    print("  ğŸ‰ ë°ëª¨ ì™„ë£Œ! output/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print("=" * 60)
    return df


if __name__ == "__main__":
    KEYWORD = "ì‚¼ì„±ì „ì"
    df = run_demo(keyword=KEYWORD)

    print("\nğŸ“‹ ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 6ê±´):")
    cols = ["source", "title", "score", "sentiment"]
    print(df[cols].head(6).to_string(index=False))
